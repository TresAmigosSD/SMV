#!/usr/bin/env bash
#
# Run SMV unit tests
# USAGE: smv-pytest [-t test_name] smv_args -- spark_args
#
# specifying tests with -t will run just those tests
#
# smv_args will be combined with each test's SMV args when the test is run
#
# user can specify spark args (such as --master, --class or --jar to override the fat jar selection)
# the rest of the arguments are the standard SmvApp arguments.

set -e
SMV_TOOLS="$(cd "`dirname "$0"`"; pwd)"
source $SMV_TOOLS/_env.sh
source $SMV_TOOLS/_pyenv.sh

if [ "$1" = "-h" ]; then
  show_run_usage_message `basename $0`
  exit 0
fi

# When run test, use local log4j config so that we can turn on DEBUG log level
LOG_CONF_FILE="${SMV_HOME}/log4j.properties"
SPARK_ARGS=("${SPARK_ARGS[@]}" "--conf" "spark.driver.extraJavaOptions=-Dlog4j.configuration=file://${LOG_CONF_FILE}")

run_pyspark_with ${SMV_TOOLS}/../src/main/python/scripts/runtests.py
