#!/usr/bin/env bash
#
# Run SMV unit tests
# USAGE: smv-pytest [-t test_name] smv_args -- spark_args
#
# specifying tests with -t will run just those tests
#
# smv_args will be combined with each test's SMV args when the test is run
#
# user can specify spark args (such as --master, --class or --jar to override the fat jar selection)
# the rest of the arguments are the standard SmvApp arguments.

set -e
THIS_FILE_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
source "${THIS_FILE_DIR}/_env.sh"
SMV_TOOLS="$(get_smv_tools_dir)"

if [ "$1" = "-h" ]; then
  show_run_usage_message `basename $0`
  exit 0
fi

# When run test, use local log4j config so that we can turn on DEBUG log level
LOG_CONF_FILE="${SMV_HOME}/log4j.properties"
SPARK_ARGS=("${SPARK_ARGS[@]}" "--conf" "spark.driver.extraJavaOptions=-Dlog4j.configuration=file://${LOG_CONF_FILE}")

echo "DEBUG SPARK_ARGS = ${SPARK_ARGS[*]}"
run_pyspark_with ${SMV_TOOLS}/../src/main/python/scripts/runtests.py
